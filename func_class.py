import astropy.units as u
import astropy.constants as c
from astropy.coordinates import SkyCoord, search_around_sky
from astropy.time import Time
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import pandas as pd
import glob
from astropy.io import fits
from itertools import combinations
import pickle
from astropy.cosmology import WMAP9 as cosmo
import seaborn as sns
from astropy.table import Table

class photometry_DataFrames:
    """
    Class of functions for loading in DataFrames from the photometry, designed for CEERS pipeline. No proprietary CEERS 
    photometric files are included here.
    ----
    Methods
    ----
    ___get_color_table___(dfi, obj = False):
            Generates a DataFrame of the colors that can be created with the input DataFrame photometry and assotiated 
            errors on those colors, reported through error propogation.
            
    ___load_photometry___(path, photz_path, chi_path, zgrid_path, template_path, ignore_HST = True):
            Initializes a Pandas DataFrame with photometry information for given FITS files from both
            NIRCam pipeline reducations and EAZY photometric fitting outputs.
    """

    def get_color_table(dfi, obj = False):
        """
        Generates a DataFrame of the colors that can be created with the input DataFrame photometry and assotiated 
        errors on those colors, reported through error propogation.

        Parameters
        ---
        dfi: pandas DataFrame, 
            generated by load_photometry function

        obj: optional
            if obj = True, Object identifiers are included in output DataFrame

        Returns
        ---
        df: pandas DataFrame
            contains all possible color combinations and their respective errors
        -----
        KEYS
        -----

        Color keys: 

            Keys for colors have the for FX-FY where x and y indicate filter names. We assume input flux in in nJy
            and convert to magnitude colors as -2.5 x log_10(Filter 1 / Filter 2)

            Through error propogation, the error on a given color is: 
            SQRT((-2.5/ln(10) (1/Filter 1)^2 (Filter 1 Error)^2) + (-2.5/ln(10) (1/Filter 2)^2 (Filter 2 Error)^2) )

        Error keys:

            Error associated with each color is stored under a keyword representing a color + an _ERROR suffix

        """
        #Grab the filters from the DataFrame FOR NO HST DATA!! CHANGE INDEX IF FILTERS ARE ADDED
        filters = dfi.keys()[3:16]
        #Initialize an empty DataFrame
        df = pd.DataFrame({})
        #Loop through all possible combinations of 2 filters
        for i in combinations(filters, 2):
            #Check if either of the elements associated with the filter are NaN
            strng0 = float(i[0].split('F')[1])
            strng1 = float(i[1].split('F')[1])
            #Only compute colors that are blue-red
            if strng0<strng1:
                if np.nansum(dfi[f'{i[0]}'])!= 0 and np.nansum(dfi[f'{i[1]}']) !=0:
                    #If neither are NaN, add the color to the DataFrame
                    f0 = dfi[f'{i[0]}']
                    f1 = dfi[f'{i[1]}']
                    df[f'{i[0]} - {i[1]}'] = -1*2.5*np.log10((f0)/(f1))
                    f0_err = dfi[f'{i[0]}_ERROR']
                    f1_err =  dfi[f'{i[1]}_ERROR']
                    error = np.sqrt(((((-2.5)/(np.log(10)))*(1/f0))**2)*((f0_err)**2) + ((((2.5)/(np.log(10)))*(1/f1))**2)*((f1_err)**2) )
                    df[f'{i[0]} - {i[1]}_ERROR'] = error
                else:
                    #If either is NaN, let the color value be NaN
                    df[f'{i[0]} - {i[1]}'] = np.nan
                    df[f'{i[0]} - {i[1]}_ERROR'] = np.nan
        if obj == True:
            df['Object'] = dfi['Object']
        return df, filters

    def load_photometry(path, photz_path, chi_path, zgrid_path, template_path, ignore_HST = True):
        """
        Initializes a Pandas DataFrame with photometry information for given FITS files from both
        NIRCam pipeline reducations and EAZY photometric fitting outputs.

        Parameters
        ---
        path: string 
            absolute path to a CEERS_v0.51.2_photom.fits

        photz_path: string 
            absolute path to CEERS_v0.51.2_photz_quantities.fits

        chi_path: string 
            absolute path to CEERS_v0.51.2_photz_chi2.fits

        zgrid_path: string 
            absolute path to CEERS_v0.51.2_photz_zgrid.fits

        template_path: string
            absolute path to CEERS_v0.51.2_photz_templates.fits

        ignore_HST: bool
            default True, ignores HST photometric filters in photometry files when set to True

        Returns
        ---
        df: pandas DataFrame
            DataFrame containing photometric information for each source. Each row indicates one source. The
            column names indicate the following:

            RA: Right Ascension of source in decimal degrees 

            DEC: Declination of source in decimal degrees 

            Region: either a 1 or 2 indicating if the source appears in the region of lesser Right Ascension (2)
                    or the region of greater Right Ascension (1)

            F115: Source flux in 115 filter, units of nJy 

            F150: Source flux in 150 filter, units of nJy

            F200: Source flux in 200 filter, units of nJy

            F277: Source flux in 277 filter, units of nJy

            F356: Source flux in 356 filter, units of nJy

            F410: Source flux in 410 filter, units of nJy 

            F444: Source flux in 444 filter, units of nJy 

            F606 : Source flux in 60.6 filter, units of nJy (Hubble Fitler)

            F814 : Source flux in 81.4 filter, units of nJy (Hubble Filter)

            F105: Source flux in 105 filter, units of nJy (Hubble Filter)

            F125: Source flux in 125 filter, units of nJy (Hubble Filter)

            F140: Source flux in 140 filter, units of nJy (Hubble Filter)

            F160: Source flux in 160 filter, units of nJy (Hubble Filter)

            F115_ERROR: Error in 115 filter flux, units of nJy 

            F150_ERROR: Error in 150 filter flux, units of nJy

            F200_ERROR: Error in 200 filter flux, units of nJy

            F277_ERROR: Error in 277 filter flux, units of nJy 

            F356_ERROR: Error in 356 filter flux, units of nJy

            F410_ERROR: Error in 410 filter flux, units of nJy 

            F444_ERROR: Error in 444 filter flux, units of nJy

            F606_ERROR: Error in 60.6 filter flux, units of nJy

            F814_ERROR: Error in 81.4 filter flux, units of nJy 

            F105_ERROR: Error in 105 filter flux, units of nJy

            F125_ERROR: Error in 125 filter flux, units of nJy 

            F140_ERROR: Error in 140 filter flux, units of nJy 

            F160_ERROR: Error in 160 filter flux, units of nJy 

            Pointing: integer photometric pointing 

            Object: photometric identifier of form 'nircamX-Y' where 'X' is the photometric pointing and 'Y'
                is the catalog identifier from Finkelstein 2023

            Former_Names: catalog identifier from previous photometry catalog

            X: x spatial coordinate in filter

            Y: y spatial coordinate in filter

            PHOTOM_RED_SHIFT: Best photometric redshift 

            Min_Chi2: The chi squared value associated with the best fit redshift 

            Lowest_Chi2: The 10 lowest chi squared values for the 10 best photometric redshift fits

            Lowest_Chi2_Z: The 10 best fit photometric redshift values

            A: semimajor axis 

            B: semiminor axis 

            ze_lower: lower bound of best fit photometric redshift error 

            ze_upper: upper bound of best fit photometric redshift error


        """
        undet = []
        #Opening the file
        hdu1 = fits.open(path)
        #Defining HST filter names
        HST_filters = ['F140', 'F140_ERROR', 'F814', 'F606', 'F105', 'F125', 'F160', 'F814_ERROR', 'F606_ERROR', 
                  'F105_ERROR', 'F125_ERROR', 'F160_ERROR']
        #Defining empty lists to store data
        filters= []
        #Looping through each of the keywords in the .fits file
        for key in hdu1[1].columns:
            #If the keyword starts with an F and has type D,
            if key.name[0] == 'F' and key.format == 'D':
                #Check that the filter contains data and not just NaN values
                #This is the first instance of byte swapping in this code. This is necessary when
                #switching from a FITS input to a pandas DataFrame due to byte order support with Pandas.
                #If this byte swapping is absent, an error for big endian buffers on a little endian 
                #compiler will raise.
                if np.nansum(hdu1[1].data[f'{key.name}'].byteswap().newbyteorder()) !=0:
                    #Add the filter to the filter list
                    filters.append(key.name)


        #Loop through the x positions of the data points

        #Initalize a pandas Data Frame with the RA and DEC positional coordinates
        df = pd.DataFrame({'RA': hdu1[1].data['RA'].byteswap().newbyteorder(), 
                           'DEC': hdu1[1].data['DEC'].byteswap().newbyteorder()})
        #Add the region flags to the DataFrame
        flags = []
        for x in hdu1[1].data['X'].byteswap().newbyteorder():
            #Check if the position is in the right of the frame
            if x > 5000:
                #Flag this as region 2
                flags.append(2)
            #Flag other points as region 1
            else:
                flags.append(1)
        df['Region'] = flags

        filters = filters[0::2]

        #Add each filter to the DataFrame, check if user wants to ignore the HST filter
        for f in filters:
            fstrng = 'F'+f.split('_')[1]
            if ignore_HST == False:
                df[fstrng] = hdu1[1].data[f].byteswap().newbyteorder()
            else:
                if fstrng not in HST_filters:
                    df[fstrng] = hdu1[1].data[f].byteswap().newbyteorder()

        for f in filters:
            strng = 'F' + f.split('_')[1] + '_ERROR'
            if ignore_HST == False:
                df[strng] = hdu1[1].data['FLUXERR_' + f.split('_')[1]].byteswap().newbyteorder()
            else:
                if strng not in HST_filters:
                    df[strng] = hdu1[1].data['FLUXERR_' + f.split('_')[1]].byteswap().newbyteorder()
        #Match the sources to the rainbows data, use the index array idk to order the rainbows 
        #data so that it can be added to the DataFrame in the correct order
        pointing = hdu1[1].data['FIELD'].byteswap().newbyteorder()
        ids = hdu1[1].data['ID'].byteswap().newbyteorder()
        formers = hdu1[1].data['ID_V0P2'].byteswap().newbyteorder()
        onames = []
        for i in range(len(ids)):
            p = pointing[i]
            ob = ids[i]
            onames.append('nircam'+str(p)+'-'+str(ob))
        df['Pointing'] = pointing

        df['Object'] = onames
        df['Former_Names'] = formers
        #Adding the pixel coordinates
        df['X'] = hdu1[1].data['X'].byteswap().newbyteorder()
        df['Y'] = hdu1[1].data['Y'].byteswap().newbyteorder()


        hdu2 = fits.open(photz_path)
        hdu3 = fits.open(chi_path)
        hdu4 = fits.open(zgrid_path)

        mnchis = []
        photozs = []
        low10chis = []
        low10photozs = []

        z_lower = []
        z_upper = []

        zgrid = hdu4[0].data
        length = len(hdu2[1].data['ZA'])

        for j in range(length):
            photo_z = hdu2[1].data['ZA'][j]
            photozs.append(photo_z)

            z_lower.append(hdu2[1].data['ZL68'][j])
            z_upper.append(hdu2[1].data['ZU68'][j])

            chi2 = hdu3[0].data[j]
            mn = np.min(chi2)
            mnchis.append(mn)

            low10 = list(sorted(chi2)[0:10])
            low10_rs = []

            for chival in low10:
                x = np.where(chi2 == chival)[0][0]
                rs = zgrid[x]
                low10_rs.append(rs)
            low10chis.append(low10)
            low10photozs.append(low10_rs)

        df['PHOTOM_RED_SHIFT'] = photozs
        df['Min_Chi2'] = mnchis
        df['Lowest_Chi2'] = low10chis
        df['Lowest_Chi2_Z'] = low10photozs
        df['A'] = hdu1[1].data['A_IMAGE'].byteswap().newbyteorder()
        df['B'] = hdu1[1].data['B_IMAGE'].byteswap().newbyteorder()
        df['ze_lower'] = z_lower
        df['ze_upper'] = z_upper
        #un-comment hdu line to return FITS header for testing stuff.
        return df#, hdu1[1]
    
class SED_plotting:
    """
    Functions used for plotting Spectra Energy Distributions (SEDs) designed for CEERS photometry
    
    ---
    Methods
    ---
    ___jon_plot___(rs = None): Plots expected prominant emission lines as they varry through redshifts and i
            ndicates where a specified
            redshift will land on this plot. Classic version of pre-JWST proposal figures, adopted from 
            IDL code written by Dr. Jonathan Trump
            
    ___plot_class___(classif, dfc, log = False, lt = 0, rt = 0):Plots all SEDs of objects with a particular 
            filter emission classification, not reccomended for sane data science.
    """

    def jon_plot(rs = None):
        """
        Plots expected prominant emission lines as they varry through redshifts and indicates where a specified
        redshift will land on this plot. Classic version of pre-JWST proposal figures, adopted from IDL code
        written by Dr. Jonathan Trump

        Parameters
        ---

        rs: optional, float between 0 and 10
            value of object's redshift, included in plot if specified


        Returns
        ---

        figure: plot of emission lines with redshift indicated

        """


        #plt.rcParams['ytick.right'] = plt.rcParams['ytick.labelright'] = True
        #plt.rcParams['ytick.left'] = plt.rcParams['ytick.labelleft'] = False

        font = 25
        #Defining emission line constants
        ha = 6563
        nii = 6584
        o3 = 5007
        o3_2 = 4959
        hb = 4861
        hd = 4101
        ne3 = 3870
        o2 = 3727
        ciii = 1909
        civ = 1550
        lya = 1216
        paa = 18750
        pab = 12820
        #Specifying figure size
        plt.rcParams['figure.figsize'] = (20, 10)
        # Grabbing filters for source from the DataFrame




        # Plotting spans for each of the filters
        plt.axvspan(388, 498.6, label= 'F444W', color = 'grey', alpha = .85)
        plt.axvspan(386.4, 430.1, label= 'F410M', alpha = 0.35, color = 'r', zorder = 10)
        plt.axvspan(314, 398, label= 'F356W', color = 'grey', alpha = .75)
        plt.axvspan(241.6, 312.7, label= 'F277W', color = 'grey', alpha = .65)
        plt.axvspan(79.5, 100.5, label= 'F090W', alpha = 0.2, color = 'grey', zorder = 10)

        plt.axvspan(175.5, 222.6, label= 'F200W', color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
        plt.axvspan(133.1, 166.8, label= 'F150W', color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
        plt.axvspan(101.3, 128.2, label= 'F115W', color = 'grey', alpha = 0.35)#color = 'purple', alpha = .25)


        #Making a range for the emission line calculations
        zarr = np.arange(0,100)
        #Ploting H alpha and NII lines
        plt.plot(1e-4*ha*(1+zarr)*1e2,zarr, c= 'k')
        plt.plot(1e-4*nii*(1+zarr)*1e2,zarr, c= 'k')
        #Plotting H betta and OIII lines
        plt.plot(1e-4*o3*(1+zarr)*1e2,zarr, color='darkgreen')
        plt.plot(1e-4*o3_2*(1+zarr)*1e2,zarr, color='darkgreen')
        plt.plot(1e-4*hb*(1+zarr)*1e2,zarr, color='darkgreen')



        #Plotting OII and NEIII lines
        plt.plot(1e-4*o2*(1+zarr)*1e2,zarr, color='blue')
        plt.plot(1e-4*ne3*(1+zarr)*1e2,zarr, color='blue')


        #Plotting Pa lines
        plt.plot(1e-4*paa*(1+zarr)*1e2,zarr, color='brown')
        #Plotting Pb lines
        plt.plot(1e-4*pab*(1+zarr)*1e2,zarr, color='brown')
        #Plotting Lya lines
        plt.plot(1e-4*lya*(1+zarr)*1e2,zarr, color='red')
        plt.text(100, 6.5, r'Ly$\alpha$', color = 'red', fontweight = 'bold')


        #Plotting CIV lines
        #plt.plot(1e-4*civ*(1+zarr)*1e2,zarr, color='red', label = r'CIV')
        #Plottinh CIII lines
        #plt.plot(1e-4*ciii*(1+zarr)*1e2,zarr, color='red', label = r'CIII')

        #Adding text to all emission lines
        plt.text(400, 5.25, r'H$\alpha$ + [NII]', rotation = 20, c = 'k', zorder = 1, fontsize = font)
        plt.text(450, 8.5, r'H$\beta$+[OIII]', rotation = 25, c = 'darkgreen',zorder = 1, fontsize = font)
        plt.text(277, 7, '[OII]+[NeIII]', rotation = 25, c = 'b', zorder = 1, fontsize = font)

        plt.text(420, 2.5, r'Pa$\beta$', rotation = 15, c = 'brown',zorder = 1, fontsize = font)
        plt.text(420, 1.5, r'Pa$\alpha$', rotation = 15, c = 'brown', zorder = 1, fontsize = font)


        #plt.text(115, 9.25, r'Ly$\alpha$', rotation = 55, c = 'red', zorder = 1, fontsize = font)
        #plt.text(115, 7.1, r'CIV', rotation = 45, c = 'red', zorder = 1, fontsize = font)
        #plt.text(105, 4.85, r'CIII', rotation = 45, c = 'red', zorder = 1, fontsize = font)

        #If a source is not specified, simply plot the emission lines. If it is specified add it to the plot
        if rs is None:
            p = 1
           # plt.title('Lines of Interest')
        else:
            #Adding the redhsift line to the plot 
            plt.axhline(rs, color = 'k', lw = 10)
            plt.text(120, rs+.25, f'Redshift = {rs}', rotation = 0, fontweight = 'bold', zorder = 10,
                    fontsize = 20)
           # plt.title(f'Lines of Interest')
        plt.ylabel('Redshift')
        plt.xlabel('Wavelength [$\mu$m]')
        plt.axvline(4.5, 5.5)

        #Some optional things good for moving labels in proposal figures
       # ax = f.add_subplot(111)
       # ax.yaxis.tick_right()



        #plt.gca().add_patch(Rectangle((386.4,4.8),430-386,3.2,
        #                edgecolor='purple',
        #                facecolor='none',
        #                lw=4))
        ticks = [115.4, 150.1, 199.0, 278.6, 356.3, 409.2, 442.1]
        labels = [1.154, 1.501, 1.990, 2.786, 3.563, 4.092, 4.421]
        plt.xticks(ticks, labels, rotation = 45)
        plt.tick_params('y', length=10, width=1, which='minor')
        plt.ylim(1,15)
        plt.xlim(50,510);
        plt.rcParams['ytick.right'] = plt.rcParams['ytick.labelright'] = False
        plt.rcParams['ytick.left'] = plt.rcParams['ytick.labelleft'] = True
       # plt.legend(ncols = 4, loc = 'upper center')
    
    def plot_class(classif, dfc, log = False, lt = 0, rt = 0):
        """
        Plots all SEDs of objects with a particular filter emission classification, not reccomended for
        sane data science.

        Parameters
        ---
        classif: string
            classification string of form 'sFILTER-DUST', for exapmple 's410-nd' to indicate a
            source with a spike in F410M with no significant dust reddening

        dfc: pandas DataFrame
            DataFrame from the load_photometry function to sample SED data from

        log: bool, optional
            when set to True, plots the SEDs on log scales

        lt: optional, starts plotting at this index in the DataFrame

        rt: optional, stops plotting at this index in the DataFrame

        Returns
        ---

        matplitlib figures with SEDs of associated sources

        """
        #Add text boxes here
        #xpos = -40
        #ypos = 1000
        #let = 'C'


        plt. style. use('default')
        plt.rcParams['figure.figsize'] = (10, 10)
        plt.rc('axes', labelsize=27)
        #plt.rc('axes', labelweight='bold')
        plt.rc('axes', titlesize=30)
        plt.rc('axes', titleweight='normal')
        plt.rc('font', family='sans-serif')
        plt.rcParams.update({'font.size': 20})


        plt.rcParams['figure.figsize'] = (10, 5)

        shape_key = 'Shape'


        plt.rcParams['figure.figsize'] = (10, 5)
        #plot_sources(remaining['Object'], remaining, df_col6, 6)
        df = dfc
        sources = dfc[dfc[shape_key] == classif]['Object']
        #plt.rcParams['figure.figsize'] = (20, 10)
        #Grab filters from DataFrame
        HST_filters = [140.0, 81.4, 60.6, 105.0, 125.0,  160.0]

        ra = []
        dec = []
        zs = []
        ps = []
        #redshifts = []
        fs = []
        fs_strings = []
        a=dfc.index[0]
        for key in df.loc[a][3:11].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=3
        stop=16
        stop2 = 29
        f_final = []
        for f in fs:
            if f>600:
                f_final.append(f*.1)
            else:
                f_final.append(f)

        #Create a colormap 
        colormap = plt.cm.gist_ncar
        colors = [colormap(i) for i in np.linspace(0, 1,len(sources)+2)][1:-1]
        #Create an SED for each of the sources
        i=0
        n=0
        rss = []
        for obj in sources:

            props = dict(boxstyle = 'square', facecolor = 'wheat', alpha = 0.2)
           ##### plt.text(xpos, ypos, let, size = 'large', bbox = props)

            #Increase the iteration tracker, grab the DataFrame for just this object
            n+=1
            #print(shapes[i])
            mk = np.array(df['Object']) == np.array(obj)
            a = df[mk]
            #Get the redshift and filters
            rs = a['PHOTOM_RED_SHIFT'].values[0]
            ra.append(a['RA'].values[0])
            dec.append(a['DEC'].values[0])
            rss.append(rs)
            zs.append(rs)
            filters = np.array(a.keys()[start:stop].values)
            filter_er = np.array(a.keys()[stop:stop2].values)
            #Mask the data so all filter values are greater than 3 times their error
            mask = (a[filters].values[0] > (3*a[filter_er].values[0]))& (a[filter_er].values[0]>0) 
            #Sort the data so the SED plot connects from left to right, regardless of filter input order
            z = sorted(zip(np.array(f_final)[mask],a[filters].values[0][mask]))
            x=[i[0] for i in z]
            y=[i[1] for i in z]

           # print(rs)

            xerror = []
            for j in x:
                xerror.append(error_dict[j]/2)




            plt.errorbar(x,y,a[filter_er].values[0][mask], xerr = xerror, ls='none',
                        color = 'k', marker = '*', markersize = 20, zorder = 1, label = 'JWST Data',
                        markerfacecolor='r',)
                #Add the x ticks
            plt.xticks(np.array(f_final)[mask])

            itr = 0
            xvals= []
            for point in range(len(x)):
                if itr == 0:
                    if x[point] in HST_filters:
                        itr+=1
                        plt.plot(x[point], y[point], marker = '*', color = 'grey', markersize = 20, label = 'HST Data',
                                zorder = 2)
                        xvals.append(x[point])
                else:
                    if x[point] in HST_filters:
                        itr+=1
                        plt.plot(x[point], y[point], marker = '*', color = 'grey', markersize = 20)
                        xvals.append(x[point])
        plt.axvspan(241.6, 312.7,  color = 'g', alpha = .025)
        plt.axvspan(314, 398,  color = 'y', alpha = .025)
        plt.axvspan(386.4, 430.1,  alpha = 0.025, color = 'orange')
        plt.axvspan(388, 498.6,  color = 'r', alpha = .025)
        plt.axvspan(175.5, 222.6,  color = 'grey', alpha = 0.055)#color = 'cyan', alpha = .25)
        plt.axvspan(133.1, 166.8,  color = 'grey', alpha = 0.045)#color = 'blue', alpha = .25)
        plt.axvspan(101.3, 128.2,  color = 'grey', alpha = 0.025)#color = 'purple', alpha = .25)

        plt.ylabel('Flux (nJy)')

        #140.0, 81.4, 60.6, 105.0, 125.0,  160.0

        labs = {'81.4':.80, '140.0':1.39, '60.6':.59, '105.0':1.05, '125.0':1.25, '160.0':1.54}
        ticks = [115.4, 150.1, 199.0, 278.6, 356.3, 409.2, 442.1]
        labels = [1.15, 1.50, 1.99, 2.78, 3.56, 4.09, 4.42]
        for v in xvals:
            ticks.append(v)
            labels.append(labs[str(v)])

        plt.xticks(ticks, labels, rotation = 90, fontsize = 14)


       # xlabels = np.around(np.array(x)/100,2)
        if log == True:
            plt.yscale("log")
        plt.xlabel(r'Wavelength [$\mu$m]')
       # plt.xticks(x, xlabels, 
       #            rotation = 90, fontsize = 16)
        r = a['RA'].values[0]
        d = a['DEC'].values[0]
        p = a['Pointing'].values[0]
        ps.append(p)
        #print(r,d)
        tenxs = a['Lowest_Chi2_Z'].values[0]
        tenrs = a['Lowest_Chi2'].values[0]
        ###LEGEND CONTROL
        plt.legend(loc = 'upper left')
        plt.tick_params('y', length=20, width=2, which='major')
        plt.tick_params('y', length=10, width=1, which='minor')
           # plt.legend()
        plt.title(f'{obj} Zphot = {round(rs,2)}')
        i+=1
               # plt.show()
               # plt.close()
               # plt.figure();

        plt.rcParams['figure.figsize'] = (10, 5)
        plt.figure()
        plt.hist(rs)
        plt.figure()
        #ratio = all_eelgs[shape_bool]['F356']/all_eelgs[shape_bool]['F444']

        plt.scatter(ra, dec, c = zs, zorder = 20,
                   s = 20, cmap = 'Paired')
        plt.colorbar()

        if lt == 0 and rt == 0:
            lim = None
        else:
            rstot = len(rss)
            inside = len(np.array(rss)[(np.array(rss)>lt) & (np.array(rss)<rt)])
            print(rstot, inside)


        for p in range(1,10):
            plt.scatter(df_new['RA'][df_new['Pointing'] == p], df_new['DEC'][df_new['Pointing'] == p], zorder = 0, 
                       alpha = 1, c = 'k')


        plt.gca().invert_xaxis()
        plt.figure()

def plot_em_all(df):
    """
    Takes all sources in a pandas DataFrame and plots their SEDS in one plot. (crazy person activity BTW)
    
    Parameters
    ---
    df: pandas DataFrame
        DataFrame containing the sources to be plotted
    
    Returns
    ---
    Matplotlib figure containing all SEDs
    
    """
    plt.rcParams['figure.figsize'] = (20, 20)
    #plot_sources(remaining['Object'], remaining, df_col6, 6)
    df = df_new[msk][bool_mask][ew_bool][cutmask]
    sources = df_new[msk][bool_mask][ew_bool][cutmask]['Object']
    #plt.rcParams['figure.figsize'] = (20, 10)
    #Grab filters from DataFrame
    fs = []
    fs_strings = []
    a=df.index[0]
    c=0


    fs = []
    fs_strings = []

    for key in df.loc[a][3:16].keys():
        fs.append(float(key.split('F')[1]))
        fs_strings.append(key)
    start=3
    stop=16
    stop2 = 29
    f_final = []
    for f in fs:
        if f>600:
            f_final.append(f*.1)
        else:
            f_final.append(f)

    #Create a colormap 
    colormap = plt.cm.gist_ncar
    colors = [colormap(i) for i in np.linspace(0, 1,len(sources)+2)][1:-1]
    #Create an SED for each of the sources
    i=0
    n=0
    for obj in sources:
        #Increase the iteration tracker, grab the DataFrame for just this object
        n+=1
        #print(shapes[i])
        mk = np.array(df['Object']) == np.array(obj)
        a = df[mk]
        #Get the redshift and filters
        rs = a['PHOTOM_RED_SHIFT']
        filters = np.array(a.keys()[start:stop].values)
        filter_er = np.array(a.keys()[stop:stop2].values)
        #Mask the data so all filter values are greater than 3 times their error
        mask = (a[filters].values[0] > (3*a[filter_er].values[0]))& (a[filter_er].values[0]>0) 
        #Sort the data so the SED plot connects from left to right, regardless of filter input order
        z = sorted(zip(np.array(f_final)[mask],a[filters].values[0][mask]))
        x=[i[0] for i in z]
        y=[i[1] for i in z]
        plt.errorbar(x,y,a[filter_er].values[0][mask], label = f'Redshift = {rs.values[0]}, {obj}',
                    color = colors[n-1])
            #Add the x ticks
        plt.xticks(np.array(f_final)[mask])





    #Add 277, 356, 410, and 444 filters
    plt.axvspan(314, 398, label= 'F356', color = 'y', alpha = .25)
    plt.axvspan(386.4, 430.1, label= 'F410', alpha = 0.25, color = 'orange')
    plt.axvspan(388, 498.6, label= 'F444', color = 'r', alpha = .25)
    plt.axvspan(241.6, 312.7, label= 'F277', color = 'g', alpha = .25)
    #Add titles and labels
    plt.title(f'Sources of Interest All pointings')
    plt.ylabel('Flux (nJy)')
    plt.yscale("log")
    plt.xlabel('Filter')
    plt.xticks(rotation = 45)
    #plt.legend()
    plt.tick_params('y', length=20, width=2, which='major')
    plt.tick_params('y', length=10, width=1, which='minor')
    i+=1
def get_sed(obj, df, log = False, lt = 0, rt = 0):
    
    xpos = -40
    ypos = 1000
    let = 'C'
    plt. style. use('default')
    plt.rcParams['figure.figsize'] = (10, 10)
    plt.rc('axes', labelsize=27)
    #plt.rc('axes', labelweight='bold')
    plt.rc('axes', titlesize=30)
    plt.rc('axes', titleweight='normal')
    plt.rc('font', family='sans-serif')
    plt.rcParams.update({'font.size': 20})

    
    plt.rcParams['figure.figsize'] = (10, 5)
    
    
    shape_key = 'Pure Shape'
    dfc = df
    
    

    plt.rcParams['figure.figsize'] = (10, 5)
    #plot_sources(remaining['Object'], remaining, df_col6, 6)
    #df = dfc
    dat = df[df['Object'] == obj]
    #plt.rcParams['figure.figsize'] = (20, 10)
    #Grab filters from DataFrame
    HST_filters = [140.0, 81.4, 60.6, 105.0, 125.0,  160.0]

    ra = []
    dec = []
    zs = []
    ps = []
    #redshifts = []
    fs = []
    fs_strings = []
    a=dfc.index[0]
    for key in df.loc[a][3:16].keys():
        fs.append(float(key.split('F')[1]))
        fs_strings.append(key)
    start=3
    stop=16
    stop2 = 29
    f_final = []
    for f in fs:
        if f>600:
            f_final.append(f*.1)
        else:
            f_final.append(f)

    #Create a colormap 
    colormap = plt.cm.gist_ncar
    colors = [colormap(i) for i in np.linspace(0, 1,len(sources)+2)][1:-1]
    #Create an SED for each of the sources
    i=0
    n=0
    rss = []
   # for obj in sources[0:45]:

   # props = dict(boxstyle = 'square', facecolor = 'wheat', alpha = 0.2)
   ##### plt.text(xpos, ypos, let, size = 'large', bbox = props)

    #Increase the iteration tracker, grab the DataFrame for just this object
    n+=1
    #print(shapes[i])
    mk = np.array(df['Object']) == np.array(obj)
    a = df[mk]
    #Get the redshift and filters
    rs = a['PHOTOM_RED_SHIFT'].values[0]
    ra.append(a['RA'].values[0])
    dec.append(a['DEC'].values[0])
    rss.append(rs)
    zs.append(rs)
    filters = np.array(a.keys()[start:stop].values)
    filter_er = np.array(a.keys()[stop:stop2].values)
    #Mask the data so all filter values are greater than 3 times their error
    mask = (a[filters].values[0] > (3*a[filter_er].values[0]))& (a[filter_er].values[0]>0) 
    #Sort the data so the SED plot connects from left to right, regardless of filter input order
    z = sorted(zip(np.array(f_final)[mask],a[filters].values[0][mask]))
    x=[i[0] for i in z]
    y=[i[1] for i in z]

   # print(rs)

    xerror = []
    for j in x:
        xerror.append(error_dict[j]/2)




    plt.errorbar(x,y,a[filter_er].values[0][mask], xerr = xerror, ls='none',
                color = 'k', marker = '*', markersize = 20, zorder = 1, label = 'JWST Data',
                markerfacecolor='r')
        #Add the x ticks
    plt.xticks(np.array(f_final)[mask])

    itr = 0
    xvals= []
    for point in range(len(x)):
        if itr == 0:
            if x[point] in HST_filters:
                itr+=1
                plt.plot(x[point], y[point], marker = '*', color = 'grey', markersize = 20, label = 'HST Data',
                        zorder = 2)
                xvals.append(x[point])
        else:
            if x[point] in HST_filters:
                itr+=1
                plt.plot(x[point], y[point], marker = '*', color = 'grey', markersize = 20)
                xvals.append(x[point])
    plt.axvspan(241.6, 312.7,  color = 'g', alpha = .25)
    plt.axvspan(314, 398,  color = 'y', alpha = .25)
    plt.axvspan(386.4, 430.1,  alpha = 0.25, color = 'orange')
    plt.axvspan(388, 498.6,  color = 'r', alpha = .25)
    plt.axvspan(175.5, 222.6,  color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
    plt.axvspan(133.1, 166.8,  color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
    plt.axvspan(101.3, 128.2,  color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)
    #Add titles and labels
    #plt.title(f'Sources of Interest All pointings Shape {cs[num]}')
    #plt.title(f'Sources of Similar SED Shape \n{n} sources')
    #plt.title(f'z = {np.mean(rss)}')
    plt.ylabel('Flux (nJy)')

    140.0, 81.4, 60.6, 105.0, 125.0,  160.0

    labs = {'81.4':.80, '140.0':1.39, '60.6':.59, '105.0':1.05, '125.0':1.25, '160.0':1.54}
    ticks = [115.4, 150.1, 199.0, 278.6, 356.3, 409.2, 442.1]
    labels = [1.15, 1.50, 1.99, 2.78, 3.56, 4.09, 4.42]
    for v in xvals:
        ticks.append(v)
        labels.append(labs[str(v)])

    plt.xticks(ticks, labels, rotation = 90, fontsize = 14)


   # xlabels = np.around(np.array(x)/100,2)
    if log == True:
        plt.yscale("log")
    plt.xlabel(r'Wavelength [$\mu$m]')
   # plt.xticks(x, xlabels, 
   #            rotation = 90, fontsize = 16)
    r = a['RA'].values[0]
    d = a['DEC'].values[0]
    p = a['Pointing'].values[0]
    ps.append(p)
    #print(r,d)
    tenxs = a['Lowest_Chi2_Z'].values[0]
    tenrs = a['Lowest_Chi2'].values[0]
    ###LEGEND CONTROL
    plt.legend(loc = 'upper left')
    #plt.title(f'{obj}, Redshift: {round(rs,3)} \n Ra: {r} Dec: {d} \n Four most likely z: {tenxs[0:6]}\n Corresponding chisq: {tenrs[0:6]}')
    plt.tick_params('y', length=20, width=2, which='major')
    plt.tick_params('y', length=10, width=1, which='minor')
       # plt.legend()
    plt.title(f'{obj} Zphot = {round(rs,2)}')
    plt.savefig(f'/home/kelcey/paper_plots/{obj}.pdf', bbox_inches = 'tight')
    i+=1
       # plt.show()
       # plt.close()
       # plt.figure();

    plt.rcParams['figure.figsize'] = (10, 5)
    plt.figure()
    plt.hist(rs)
    plt.figure()
    #ratio = all_eelgs[shape_bool]['F356']/all_eelgs[shape_bool]['F444']

    plt.scatter(ra, dec, c = zs, zorder = 20,
               s = 20, cmap = 'Paired')
    plt.colorbar()

    if lt == 0 and rt == 0:
        lim = None
    else:
        rstot = len(rss)
        inside = len(np.array(rss)[(np.array(rss)>lt) & (np.array(rss)<rt)])
        print(rstot, inside)


    for p in range(1,10):
        plt.scatter(df_new['RA'][df_new['Pointing'] == p], df_new['DEC'][df_new['Pointing'] == p], zorder = 0, 
                   alpha = 1, c = 'k')


    plt.gca().invert_xaxis()
    plt.figure()
    #plt.legend();
    #return ra,dec, zs, ps
    #jon_plot(mrs, dfc, source = f'Source Shape {classif}');
    
    
class photometry_selector:
    def cut_sides(df, best_df, num, dynamic = False):
        """
        Takes a DataFrame of sources and compares it to a larger DataFrame. Sources either near the edge of the 
        detected sources or within an arcsecond of a bright source are thrown out

        Parameters
        ---
        df: pandas DataFrame
            DataFrame from load_photometry function

        best_df: pandas DataFrame
            a cut version of df, only including the sources of interest

        num: integer,
            integer pointing number

        Reutrns
        ---
        figure: matplotlib figure
            plot of all data in the pointing, indicating which 

        cut_data: pandas DataFrame
            the input DataFrame, only including sources that passed cuts

        """
        #Identify two seperate regions
        plt.rcParams['figure.figsize'] = (10, 10)
        plt.figure()
        db1 = best_df
        left = df[df['Region']==1]
        right = df[df['Region']==2]
        #Find the edges of the regions, draw a cutoff around the 100 pixel coordinates around the edge
        mn_x = np.min(df['X'])+100
        lmax_x = np.max(left['X'])-100
        rmin_x = np.min(right['X'])+100
        mx_x = np.max(df['X'])-100
        mn_y = np.min(df['Y'])+100
        lmax_y = np.max(left['Y'])-100
        rmin_y = np.min(right['Y'])+100
        mx_y = np.max(df['Y'])-100
        #Create lists to store the relavent sources
        post_cut = []
        too_close = []
        #For each of the sources in the smaller DataFrame
        for i in db1.index:
            #Get the DataFrame only includin that source
            dfsource = db1.loc[i]
            #Check if it is in the leftmost region, if it lies inside the cut region, keep the source
            if dfsource['Region'] == 1:
                if dfsource['X']>mn_x:
                    if dfsource['X']<lmax_x:
                        if dfsource['Y']>mn_y:
                            if dfsource['Y']<lmax_y:
                                post_cut.append(i)
            #If the source is in the rightmost region, check if it passes the cuts for that region
            if dfsource['Region'] == 2:  
                if dfsource['X']>rmin_x:
                    if dfsource['X']<mx_x:
                        if dfsource['Y']>rmin_y:
                            if dfsource['Y']<mx_y:
                                post_cut.append(i)
        #Plot all the sources that were observed in the region
        plt.scatter(df['RA'], df['DEC'], label = 'Data')
        #Add a gold star for sources that were eliminated due to proximity to edge
        plt.scatter(db1['RA'], db1['DEC'], c = 'gold', marker = '*', s = 200, zorder = 1, 
                    label = 'Tossed - close to edge')
        #Look only at the sources that passed the edge proximity check
        for ind in db1.loc[post_cut].index:
            dfsource = db1.loc[ind]
            ra = df.loc[ind]['RA']
            dec = df.loc[ind]['DEC']
            #Create a data frame that includes all sources but the one currntly being looped over
            l = df.drop(ind)
            ra2 = l['RA']
            dec2= l['DEC']
            #Look at all sources within one arcsecond of the source being looped over
            leftovers =l[SkyCoord(ra2*u.deg, dec2*u.deg).separation(SkyCoord(ra*u.deg,dec*u.deg))<1*u.arcsec]
            #If any sources are found to be within one arcsecond
            if len(leftovers)>0:
                #Grab the filters

                a=ind
                fs = []
                fs_strings = []
                for key in df.loc[a][3:11].keys():
                    fs.append(float(key.split('F')[1]))
                    fs_strings.append(key)
                start=3
                stop=11
                stop2 = 19
                f_final = []
                for f in fs:
                    f_final.append(f)

                #Check if the nearby source is brigther than the source of interest by 100nJy in any
                #of the observed filters. If it is, flag the source.
                flags = []
                dfsource = df.loc[ind]
                for fltr in fs_strings:
                    for i in leftovers.index:
                        if (leftovers.loc[i][fltr]-dfsource[fltr]) >100:
                            too_close.append(ind)
                            flags.append(i)
        #Plot a black star over any source thrown out because of a nearby source
        close = set(too_close)
        plt.scatter(db1.loc[post_cut].loc[close]['RA'], db1.loc[post_cut].loc[close]['DEC'], marker = '*', color = 'k', s =200,
                   label = 'Tossed-Nearby source', zorder = 500)
        #Cut the data 
        throw = db1.loc[post_cut].loc[close]
        good = []
        for ind in db1.loc[post_cut].index:
            if ind not in throw:
                good.append(ind)
        cut_data = db1.loc[good]
        #plot a red star over sources kept after cutting
        plt.scatter(db1.loc[post_cut]['RA'], db1.loc[post_cut]['DEC'], marker = '*', color = 'r', s =200,
                   label = 'Kept')
        #Add labels and title
        plt.legend()
        plt.gca().invert_xaxis()
        plt.title(f'Pointing {num} - Data Cuts')
        plt.xlabel('RA(Deg)')
        plt.ylabel('DEC(Deg)');
        return cut_data

    def get_ew(df, sources):
        """
        string
        """
        def reject_outliers(data, max_std):
            """
            other string to fill out
            """
            return data[abs(data - np.mean(data)) < max_std * np.std(data)]
        filter_widths = {115.0: 0.225 * 1e-6*u.m, 
                    150.0: 0.318* 1e-6*u.m,
                    105.0: np.nan,
                    200: 0.457* 1e-6*u.m,
                    277: 0.683* 1e-6*u.m,
                    356: 0.781* 1e-6*u.m,
                    410: 0.438* 1e-6*u.m,
                    444: 1.029* 1e-6*u.m,
                    60.6: np.nan,
                    81.4: np.nan,
                    125: np.nan,
                    140: 0.412* 1e-6*u.m,
                    160: np.nan}
        # plt.rcParams['figure.figsize'] = (10, 10)
        #sources = cut1['Object']
        hits= []
        rsh = []
        ra = []
        dec = []
        kpcs = []
        filter_arrays = []
        filter_arrays_vals = []
        filter_arrays_err = []
        k = df.index[0]
        a = df.index[0]
        fs = []
        fs_strings = []
        for key in df.loc[a][3:11].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=3
        stop=11
        stop2 = 19
        f_final = []
        for f in fs:
            f_final.append(f)

        ews_tot =[]

        ews_tot =[]
        if len(sources) == 1:
            obj = sources
        else:
            for obj in sources:
               # plt.figure()
               # n+=1
                mk = np.array(df['Object']) == np.array(obj)
                a = df[mk]
                rs = a['PHOTOM_RED_SHIFT'].values
                kpc = cosmo.kpc_proper_per_arcmin(np.array(rs))
                #mask = (a[filters].values[0] > (3*a[filter_er].values[0]))&(a[filters].values[0] >0)
                #if c ==0:
                f =  np.array(a.keys()[start:stop].values)
                filter_er = np.array(a.keys()[stop:stop2].values)
                #else:
                  #  filters = np.array(a.keys()[4:17].values)
                   # filter_er = np.array(a.keys()[18:30].values)
                mask = (a[f].values[0] > (3*a[filter_er].values[0]))#&(a[filters].values[0] >0)
               # filters = np.array(f_final)[mask]
                #if len(filters)>5:
                filter_arrays_vals.append(a[f].values[0][mask])
                filter_arrays.append(np.array(f_final)[mask])
                rsh.append(rs)
               # a
                filter_arrays_err.append(a[filter_er].values[0][mask])
                max_std = 1
                smooth = reject_outliers(a[f].values[0][mask], 1)
                #cv = np.mean(smooth)
                ews = []
                for inn in range(len(a[f].values[0][mask])):
                    #z = a['PHOTOM_RED_SHIFT'].values
                    ftr = np.array(f_final)[mask][inn]
                    fval = a[f].values[0][mask][inn]
                    ewrf = (filter_widths[ftr]*(((fval*1e-9*u.Jy)) - (np.mean(smooth)*1e-9*u.Jy))/(np.mean(smooth)*1e-9*u.Jy))
                    if ewrf>0:

                        ew = ewrf#/(1+z)
                        ews.append(ew.to(u.AA).value)
                       # print(ewrf>0)
                    else:
                        #print(ew)
                        ews.append(np.nan)
                try:
                    ews_tot.append(np.nanmax(ews))
                except:
                    ews_tot.append(np.nan)


        return ews_tot

    def get_ew_277(df, sources):
        """
        I added this on as an extension of get_ew because we added an extra filter at the last minute! Check that function 
        for specifics.
        """
        def reject_outliers(data, max_std):
            return data[abs(data - np.mean(data)) < max_std * np.std(data)]
        red = [277.0]
        filter_widths = {115.0: 0.225 * 1e-6*u.m, 
                    150.0: 0.318* 1e-6*u.m,
                    105.0: np.nan,
                    200: 0.457* 1e-6*u.m,
                    277: 0.683* 1e-6*u.m,
                    356: 0.781* 1e-6*u.m,
                    410: 0.438* 1e-6*u.m,
                    444: 1.029* 1e-6*u.m,
                    60.6: np.nan,
                    81.4: np.nan,
                    125: np.nan,
                    140: 0.412* 1e-6*u.m,
                    160: np.nan}
        # plt.rcParams['figure.figsize'] = (10, 10)
        #sources = cut1['Object']
        hits= []
        rsh = []
        ra = []
        dec = []
        kpcs = []
        filter_arrays = []
        filter_arrays_vals = []
        filter_arrays_err = []
        k = df.index[0]

        fs = []
        fs_strings = []

        for key in df.loc[k][3:10].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=3
        stop=10
        stop2 = 17
        f_final = []
        for f in fs:
            f_final.append(f)

        ews_tot =[]
        if len(sources) == 1:
            obj = sources
        else:
            for obj in sources:
               # plt.figure()
               # n+=1
                mk = np.array(df['Object']) == np.array(obj)
                a = df[mk]
                rs = a['PHOTOM_RED_SHIFT'].values
               # kpc = cosmo.kpc_proper_per_arcmin(np.array(rs))
                #mask = (a[filters].values[0] > (3*a[filter_er].values[0]))&(a[filters].values[0] >0)
                #if c ==0:
                f =  np.array(a.keys()[start:stop].values)
                filter_er = np.array(a.keys()[stop:stop2].values)
                #else:
                  #  filters = np.array(a.keys()[4:17].values)
                   # filter_er = np.array(a.keys()[18:30].values)
                mask = (a[f].values[0] > (3*a[filter_er].values[0]))#&(a[filters].values[0] >0)
               # filters = np.array(f_final)[mask]
                #if len(filters)>5:
                filter_arrays_vals.append(a[f].values[0][mask])
                filter_arrays.append(np.array(f_final)[mask])
                rsh.append(rs)
               # a
                filter_arrays_err.append(a[filter_er].values[0][mask])
                max_std = 1
                smooth = reject_outliers(a[f].values[0][mask], 1)
                #cv = np.mean(smooth)
                ews = []
                for inn in range(len(a[f].values[0][mask])):
                    z = a['PHOTOM_RED_SHIFT'].values
                    ftr = np.array(f_final)[mask][inn]
                    fval = a[f].values[0][mask][inn]
                    ewrf = (filter_widths[ftr]*(((fval*1e-9*u.Jy)) - (np.mean(smooth)*1e-9*u.Jy))/(np.mean(smooth)*1e-9*u.Jy))
                    if ftr in red:
                        if ewrf>0:

                            ew = ewrf#/(1+z)
                            ews.append(ew.to(u.AA).value)
                           # print(ewrf>0)
                        else:
                            #print(ew)
                            ews.append(np.nan)
                try:
                    ews_tot.append(np.nanmax(ews))
                except:
                    ews_tot.append(np.nan)
        ew_lists_big = 0 
        cont = 0
        spike_vals = 0
        spike_widths = 0
        return ews_tot, ew_lists_big, cont, spike_vals, spike_widths

    def get_ew_red_only_and_277(df, sources):
        """
        See get_ew for specifics
        """
        def reject_outliers(data, max_std):
            return data[abs(data - np.mean(data)) < max_std * np.std(data)]
        #Defining the filters that we consider red
        red = [277.0, 356.0, 410.0, 444.0]
        #Defining the widths of these filters
        filter_widths = {115.0: 0.225 * 1e-6*u.m, 
                    150.0: 0.318* 1e-6*u.m,
                    105.0: np.nan,
                    200: 0.457* 1e-6*u.m,
                    277: 0.683* 1e-6*u.m,
                    356: 0.781* 1e-6*u.m,
                    410: 0.438* 1e-6*u.m,
                    444: 1.029* 1e-6*u.m,
                    60.6: np.nan,
                    81.4: np.nan,
                    125: np.nan,
                    140: 0.412* 1e-6*u.m,
                    160: np.nan}
        #Defining lists to store data
        hits = []
        rsh = []
        ra = []
        dec = []
        kpcs = []
        ew_lists_big = []
        filter_arrays = []
        filter_arrays_vals = []
        filter_arrays_err = []
        k = df.index[0]
        #Defining filters
        fs = []
        fs_strings = []
        for key in df.loc[k][3:10].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=3
        stop=10
        stop2 = 17
        f_final = []
        for f in fs:
            f_final.append(f)
        #Defining lsits for equivalent widths
        ews_tot =[]
        cont = []
        spike_vals = [] 
        spike_widths = []
        #Check if we have been fed just one object. If so, we just want to iterate over this.
        if len(sources) == 1:
            obj = sources
        else:
            #looping over each of the sources
            for obj in sources:
                #Isolate the dataframe of just this object
                mk = np.array(df['Object']) == np.array(obj)
                a = df[mk]
                #Get the redshift
                rs = a['PHOTOM_RED_SHIFT'].values
                #kpc = cosmo.kpc_proper_per_arcmin(np.array(rs))
                #Get the filters and their respective errors for this source
                f =  np.array(a.keys()[start:stop].values)
                filter_er = np.array(a.keys()[stop:stop2].values)
                #Apply a limit that all real data points will be at least three times their error
                mask = (a[f].values[0] > (3*a[filter_er].values[0]))#&(a[filters].values[0] >0)
                #Add the filter values and redshifts to respective arrays
                filter_arrays_vals.append(a[f].values[0][mask])
                filter_arrays.append(np.array(f_final)[mask])
                rsh.append(rs)
                #Add the error to the correct array
                filter_arrays_err.append(a[filter_er].values[0][mask])
                #Set the maximum allowed standard deviation before a spike is not considered to be part of the continuum
                max_std = 1
                #smooth is the isolated continuum
                smooth = reject_outliers(a[f].values[0][mask], 1)
                #Make a list to hold the equivalent widths for just this object
                ews = []
                filter_vals = []
                fwidth = []
                #Iterate over each filter
                for inn in range(len(a[f].values[0][mask])):
                    #z = a['PHOTOM_RED_SHIFT'].values
                    ftr = np.array(f_final)[mask][inn]
                    fval = a[f].values[0][mask][inn]
                    ewrf = (filter_widths[ftr]*(((fval*1e-9*u.Jy)) - (np.mean(smooth)*1e-9*u.Jy))/(np.mean(smooth)*1e-9*u.Jy))
                    if ftr in red:
                        if ewrf>0:

                            ew = ewrf#/(1+z)
                            ews.append(ew.to(u.AA).value)
                            filter_vals.append(ftr)
                            fwidth.append(filter_widths[ftr])
                           # print(ewrf>0)
                        else:
                            #print(ew)
                            ews.append(np.nan)
                            filter_vals.append(ftr)
                            fwidth.append(filter_widths[ftr])
                try:
                    ews_tot.append(np.nanmax(ews))
                except:
                    ews_tot.append(np.nan)
                cont.append(smooth)
                spike_vals.append(filter_vals)
                spike_widths.append(fwidth)
        ew_lists_big, cont, spike_vals, spike_widths == 0
        return ews_tot, ew_lists_big, cont, spike_vals, spike_widths

    def get_ew_red_only(df, sources):
        """
        See get_ew
        """
        def reject_outliers(data, max_std):
            return data[abs(data - np.mean(data)) < max_std * np.std(data)]
        #Defining the filters that we consider red
        red = [356.0, 410.0, 444.0]
        #Defining the widths of these filters
        filter_widths = {115.0: 0.225 * 1e-6*u.m, 
                    150.0: 0.318* 1e-6*u.m,
                    105.0: np.nan,
                    200: 0.457* 1e-6*u.m,
                    277: 0.683* 1e-6*u.m,
                    356: 0.781* 1e-6*u.m,
                    410: 0.438* 1e-6*u.m,
                    444: 1.029* 1e-6*u.m,
                    60.6: np.nan,
                    81.4: np.nan,
                    125: np.nan,
                    140: 0.412* 1e-6*u.m,
                    160: np.nan}
        #Defining lists to store data
        hits= []
        rsh = []
        ra = []
        dec = []
        kpcs = []
        ew_lists_big = []
        filter_arrays = []
        filter_arrays_vals = []
        filter_arrays_err = []
        k = df.index[0]
        #Defining filters
        fs = []
        fs_strings = []
        for key in df.loc[k][3:10].keys():
            fs.append(float(key.split('F')[1]))
            fs_strings.append(key)
        start=3
        stop=10
        stop2 = 17
        f_final = []
        for f in fs:
            f_final.append(f)
        #Defining lsits for equivalent widths
        ews_tot =[]
        cont = []
        spike_vals = [] 
        spike_widths = []
        #Check if we have been fed just one object. If so, we just want to iterate over this.
        if len(sources) == 1:
            obj = sources
        else:
            #looping over each of the sources
            for obj in sources:
                #Isolate the dataframe of just this object
                mk = np.array(df['Object']) == np.array(obj)
                a = df[mk]
                #Get the redshift
                rs = a['PHOTOM_RED_SHIFT'].values
                #kpc = cosmo.kpc_proper_per_arcmin(np.array(rs))
                #Get the filters and their respective errors for this source
                f =  np.array(a.keys()[start:stop].values)
                filter_er = np.array(a.keys()[stop:stop2].values)
                #Apply a limit that all real data points will be at least three times their error
                mask = (a[f].values[0] > (3*a[filter_er].values[0]))#&(a[filters].values[0] >0)
                #Add the filter values and redshifts to respective arrays
                filter_arrays_vals.append(a[f].values[0][mask])
                filter_arrays.append(np.array(f_final)[mask])
                rsh.append(rs)
                #Add the error to the correct array
                filter_arrays_err.append(a[filter_er].values[0][mask])
                #Set the maximum allowed standard deviation before a spike is not considered to be part of the continuum
                max_std = 1
                #smooth is the isolated continuum
                smooth = reject_outliers(a[f].values[0][mask], 1)
                #Make a list to hold the equivalent widths for just this object
                ews = []
                filter_vals = []
                fwidth = []
                #Iterate over each filter
                for inn in range(len(a[f].values[0][mask])):
                    #z = a['PHOTOM_RED_SHIFT'].values
                    ftr = np.array(f_final)[mask][inn]
                    fval = a[f].values[0][mask][inn]
                    ewrf = (filter_widths[ftr]*(((fval*1e-9*u.Jy)) - (np.mean(smooth)*1e-9*u.Jy))/(np.mean(smooth)*1e-9*u.Jy))
                    if ftr in red:
                        if ewrf>0:

                            ew = ewrf#/(1+z)
                            ews.append(ew.to(u.AA).value)
                            filter_vals.append(ftr)
                            fwidth.append(filter_widths[ftr])
                           # print(ewrf>0)
                        else:
                            #print(ew)
                            ews.append(np.nan)
                            filter_vals.append(ftr)
                            fwidth.append(filter_widths[ftr])
                try:
                    ews_tot.append(np.nanmax(ews))
                except:
                    ews_tot.append(np.nan)
                cont.append(smooth)
                spike_vals.append(filter_vals)
                spike_widths.append(fwidth)
       # ew_lists_big, cont, spike_vals, spike_widths == 0
        return ews_tot, ew_lists_big, cont, spike_vals, spike_widths



def reject_outliers(data, max_std):
    """
    Rejects all data points outside of one standard deviation from the data, used to grab continuum around
    extreme linse
    """
    return data[abs(data - np.mean(data)) < max_std * np.std(data)]


def load_spectra(file_path):
    """
    Load the spectra from a CSV file.
    
    Parameters:
    file_path (str): Path to the CSV file.
    
    Returns:
    np.ndarray: Wavelength array.
    np.ndarray: Flux array.
    """
    hdu1 = fits.open(file_path)
    data = hdu1[1].data
    #data = pd.read_csv(file_path)
    return data['wavelength'], data['flux']

def baseline_correction(flux, window_size=101, polyorder=3):
    """
    Correct the baseline of the spectrum.
    
    Parameters:
    flux (np.ndarray): Flux array.
    window_size (int): The length of the filter window (must be odd).
    polyorder (int): The order of the polynomial used to fit the samples.
    
    Returns:
    np.ndarray: Baseline-corrected flux array.
    """
    baseline = savgol_filter(flux, window_length=window_size, polyorder=polyorder)
    corrected_flux = flux - baseline
    return corrected_flux

def identify_lines(wavelengths, flux, threshold=0.5):
    """
    Identify local maxima in the spectra as potential spectral lines.
    
    Parameters:
    wavelengths (np.ndarray): Wavelength array.
    flux (np.ndarray): Flux array.
    threshold (float): Relative threshold for peak detection.
    
    Returns:
    np.ndarray: Wavelengths of the identified lines.
    """
    peaks, _ = find_peaks(flux, height=np.max(flux) * threshold)
    return wavelengths[peaks]

def calculate_redshifts(identified_lines, rest_wavelengths, initial_redshift, tolerance=500):
    """
    Calculate the redshifts for each of the spectral lines individually.
    
    Parameters:
    identified_lines (np.ndarray): Wavelengths of identified lines.
    rest_wavelengths (dict): Rest-frame wavelengths of known lines.
    initial_redshift (float): Initial guess of the redshift.
    tolerance (float): Tolerance in angstroms for matching.
    
    Returns:
    dict: Redshifts calculated from each line.
    """
    redshifts = {}
    for line, rest_wave in rest_wavelengths.items():
        expected_wave = rest_wave * (1 + initial_redshift)
        differences = np.abs(identified_lines - expected_wave)
       # print(f"Line: {line}, Expected wavelength: {expected_wave}, Differences: {differences}")
        if np.min(differences) < tolerance:
            observed_wave = identified_lines[np.argmin(differences)]
            redshift = (observed_wave / rest_wave) - 1
            redshifts[line] = redshift
          #  print(f"Matched {line}: Observed wavelength: {observed_wave}, Calculated redshift: {redshift}")
    return redshifts
def filter_from_zwave(z, wavelength):
    """
    Function returns the photometric filter capturing the indicated wavelength in observed frame 
    at this redshift
    
    Params
    ---
    z: float, dimensionlesss
        dimensionless line of sight stretch factor due to expansion of the Universe
    wavelenth: float, in micrometers (um)
        Target wavelength
    
    
    Returns
    ---
    Filter: string identifyer for filter in CEERS (change internal wavelength table for other 
    fields or coverage)
    
    """
    
    conversion = 0.0001 #AA to um


    #Building a dictionary of the filter widths and depths
    width_dict = {60.6: np.array([(5889.2-(2189.2/2))*conversion, (5889.2+(2189.2/2))*conversion])*100, 
                  81.4: np.array([(8039.1-(1565.2/2))*conversion, (8039.1+(1565.2/2))*conversion])*100,
                  105.0: np.array([(1055.2-(265.0/2))*0.001, (1055.2+(265.0/2))*0.001])*100,
                  115.0: np.array([(1.154-(0.225/2)), (1.154+(0.225/2))]),
                  125.0: np.array([(1248.6-(284.5/2))*0.001, (1248.6+(284.5/2))*0.001])*100,
                  140.0: np.array([(1392.3-(384.0/2))*0.001, (1392.3+(384.0/2))*0.001])*100,
                  150.0: np.array([(1.501-(0.318/2)), (1.501+(0.318/2))])*100,
                  160.0: np.array([(1536.9-(268.3/2))*0.001, (1536.9+(268.3/2))*0.001])*100,
                  200.0: np.array([(1.990-(0.461/2), (1.990+(0.461/2)))])*100,
                  277.0: np.array([(2.786-(0.672/2)), (2.786+(0.672/2))])*100,
                  356.0: np.array([(3.365-(0.347/2)), (3.365+(0.347/2))])*100,
                  410.0: np.array([(4.092-(0.436/2)), (4.092+(0.436/2))])*100,
                  444.0: np.array([(4.421-(1.024/2)), (4.421+(1.024/2))])*100}
    
    val  = wavelength*(1+z)*10 #Converted to range that works will my silly dictionary
    

    tablekeys = []
    for key in width_dict.keys():
        try:
            if width_dict[key][0]<val:
                if width_dict[key][1]> val:
                    tablekeys.append('F' + f'{int(key)}')
        except:
            if width_dict[key][0][0]<val:
                if width_dict[key][0][1]> val:
                    tablekeys.append('F' + f'{int(key)}')
    return tablekeys


def plot_interplolated():
    """
    INCOMPLETE: need to adapt code so that it takes proper imports. This is mostly 
    copy/pasted from another error to preserve it.
    """



    plt.rcParams['figure.figsize'] = (20, 7)
    #plot_sources(remaining['Object'], remaining, df_col6, 6)
    df = artifactless
    sources = photids
    #plt.rcParams['figure.figsize'] = (20, 10)
    #Grab filters from DataFrame
    fs = []
    fs_strings = []
    a=df.index[0]
    c=0
    prismss = []
    mgratss = []
    scale = .1e-14
    low_min = 0
    datmin = -.01#-1e-5
    emax = 1e-1

    HST_filters = [140.0, 81.4, 60.6, 105.0, 125.0,  160.0]

    val = 3

    #mx = 

    fs = []
    fs_strings = []

    for key in df.loc[a][3:16].keys():
        fs.append(float(key.split('F')[1]))
        fs_strings.append(key)
    start=3
    stop=16
    stop2 = 29
    f_final = []
    for f in fs:
        if f>600:
            f_final.append(f*.1)
        else:
            f_final.append(f)

    #Create a colormap 

    #colormap = plt.cm.gist_ncar
    #colors = [colormap(i) for i in np.linspace(0, 1,len(sources)+2)][1:-1]

    #Create an SED for each of the sources
    i=0
    n=-1
    for obj in sources[0:1]:
        #print(obj)
        fig, (ax1, ax2, ax3) = plt.subplots(3)
        #fig.suptitle('Vertically stacked subplots')

        #UN-COMMENT FOR PLOT ALPHA LABELS
        #props = dict(boxstyle = 'square', facecolor = 'wheat', alpha = 0.2)
        #ax1.text(0.7, 150, 'E', size = 'large', bbox = props)

        n+=1
        #print(shapes[i])
        mk = np.array(df['Object']) == np.array(obj)
        a = df[mk]
        #Get the redshift and filters
        rs = a['PHOTOM_RED_SHIFT']

        try:
            specrs = zpecs[zpecs['MPTID'] == mptids[n]]['Z'].values[0]
        except:
            specrs = np.nan
        filters = np.array(a.keys()[start:stop].values)
        filter_er = np.array(a.keys()[stop:stop2].values)
        #Mask the data so all filter values are greater than 3 times their error
        mask = (a[filters].values[0] > (3*a[filter_er].values[0]))& (a[filter_er].values[0]>0) 
        #Sort the data so the SED plot connects from left to right, regardless of filter input order
        z = sorted(zip(np.array(f_final)[mask],a[filters].values[0][mask]))
        x=[i[0] for i in z]
        y=[i[1] for i in z]



        xerror = []
        for j in x:
            xerror.append(error_dict[j]/2)




        ax1.errorbar(x,y,a[filter_er].values[0][mask], xerr = xerror, ls='none',
                    color = 'k', marker = '*', markersize = 20, zorder = 1, label = 'JWST Data',
                    markerfacecolor='r',)
            #Add the x ticks
        ax1.set_xticks(np.array(f_final)[mask])

        itr = 0
        for point in range(len(x)):
            if itr == 0:
                if x[point] in HST_filters:
                    itr+=1
                    ax1.plot(x[point], y[point], marker = '*', color = 'grey', markersize = 20, label = 'HST Data',
                            zorder = 2)
            else:
                if x[point] in HST_filters:
                    itr+=1
                    ax1.plot(x[point], y[point], marker = '*', color = 'grey', markersize = 20,
                            zorder = 2)


        i+=1
        ax1.axvspan(314, 398,  color = 'y', alpha = .25)
        ax1.axvspan(386.4, 430.1,  alpha = 0.25, color = 'orange')
        ax1.axvspan(388, 498.6,  color = 'r', alpha = .25)
        ax1.axvspan(241.6, 312.7,  color = 'g', alpha = .25)

        ax1.axvspan(175.5, 222.6,  color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
        ax1.axvspan(133.1, 166.8,  color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
        ax1.axvspan(101.3, 128.2,  color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)

        ax1.legend()

        #fig.suptitle(f'{obj} \n RS = {round(rs.values[0],2)} observed in {cathits[n]} \n NIRSpec matching distance: {d2ds[n]} \nMPTID {mptids[n]}')
        fig.suptitle(f'{obj}  CEERS-{int(mptids[n])} zphot = {round(rs.values[0],2)}, zspec = {round(specrs,2)}') #observed in {cathits[n]} ')

        #plt.title(f'{obj} \n RS = {round(rs.values[0],2)} observed in {cathits[n]} \n NIRSpec matching distance: {d2ds[n]} \nMPTID {mptids[n]}')
        ax1.set_xlim(55,550)
        ax1.set_ylabel('Flux (nJy)')
        #plt.yscale("log")
        #ax1.set_xlabel('Filter')
        ax1.xaxis.tick_top()
        flabels = np.array(['F115W', 'F150W', 'F200W', 'F277W', 'F356W', 'F410M', 'F444W'])
        ax1.set_xticks(np.array([115, 150, 200, 277, 356, 410, 444]))
        ax1.set_xticklabels(flabels)
    ###

        check = 0
        pointing = cathits[n][-1][-1]
        files = glob.glob(f'/home/kelcey/JWST_test_code/updated_sources/p{pointing}/*')
        if len(files)==0:
            #print(f'Download files for source {obj}')
            check += 1
        else:
            prism = glob.glob(f'/home/kelcey/JWST_test_code/updated_sources/p{pointing}/'+
                         f'p{pointing}_PRISM_{int(mptids[n])}_*')
            #print(len(prism))
            if len(prism)!=0:
               # print('Prism available')
                if prism[0][-8] == 's':
                    d1 = prism[1]
                    d2 = prism[0]

                    hdu1 = fits.open(d1)
                    datap1 = hdu1[1].data
                    wave_1d = datap1['WAVELENGTH']
                    flx_1d  = datap1['FLUX']
                    pix_1d  = np.arange(len(wave_1d))

                    datap1 = hdu1[1].data
                    flux = []
                    for f in flx_1d:
                        if f<datmin:
                            flux.append(np.nan)
                        else:
                            flux.append(f*1e-9)

                    flux_e = []
                    for f in datap1['FLUX_ERROR']:
                        if f>emax:
                            flux_e.append(np.nan)
                        else:
                            flux_e.append(f*1e-9)

                    ax3.plot(datap1['WAVELENGTH'], flux, clip_on = False)
                    ax3.fill_between(datap1['WAVELENGTH'], np.array(flux)-np.array(flux_e), 
                         np.array(flux)+np.array(flux_e), color = 'c', alpha  = 0.35, clip_on = False)
                    ax3.axvspan(3.14, 3.98, label= 'F356', color = 'y', alpha = .25)
                    ax3.axvspan(3.864, 4.301, label= 'F410', alpha = 0.25, color = 'orange')
                    ax3.axvspan(3.88, 4.986, label= 'F444', color = 'r', alpha = .25)
                    ax3.axvspan(2.416, 3.127, label= 'F277', color = 'g', alpha = .25)

                    #Illustrate a detector gap
                    #plt.axvspan(3.26,4.78,color = 'grey', alpha = 0.75)

                    ax3.axvspan(1.755, 2.226, label= 'F200', color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
                    ax3.axvspan(1.331, 1.668, label= 'F150', color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
                    ax3.axvspan(1.013, 1.282, label= 'F115', color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)

                    ax3.set_xlabel(r'Wavelength[$\mu$m]')
                    ax3.set_ylabel(r'$F_{\lambda}$')
                    ax3.set_xlim(.55,5.50)
                    ax3.set_ylim(low_min,scale)





                    hdu = fits.open(d2)
                    datap2 = hdu[1].data
                    #55to550
                    xs = np.linspace(.55, 5.5, int(1e4))
                    spectra = np.zeros(( datap2.shape[0], int(1e4)))
                    for x in np.arange(datap2.shape[0]):
                        inter = np.interp(xs, wave_1d, datap2[x] )
                        spectra[x, :] = inter


                    vmin = np.median(datap2) - val * np.std(datap2)
                    vmax = np.median(datap2) + val * np.std(datap2)


                    ax2.imshow(spectra , cmap = 'gray', vmin = vmin, vmax = vmax, origin = 'lower', aspect = 'auto')

                    ax2.set_xticks([])
                    ax2.set_yticks([])

                elif prism[0][-8] == 'x':

                    ###
                    d1 = prism[0]
                    d2 = prism[1]

                    hdu1 = fits.open(d1)
                    datap1 = hdu1[1].data
                    wave_1d = datap1['WAVELENGTH']
                    flx_1d  = datap1['FLUX']
                    pix_1d  = np.arange(len(wave_1d))

                    datap1 = hdu1[1].data

                    flux = []
                    for f in flx_1d:
                        if f<datmin:
                            flux.append(np.nan)
                        else:
                            flux.append(f*1e-9)

                    flux_e = []
                    for f in datap1['FLUX_ERROR']:
                        if f>emax:
                            flux_e.append(np.nan)
                        else:
                            flux_e.append(f*1e-9)

                    ax3.plot(datap1['WAVELENGTH'], flux, clip_on = False)
                    ax3.fill_between(datap1['WAVELENGTH'], np.array(flux)-np.array(flux_e), 
                         np.array(flux)+np.array(flux_e), color = 'c', alpha  = 0.35, clip_on = False)
                    ax3.axvspan(3.14, 3.98, label= 'F356', color = 'y', alpha = .25)
                    ax3.axvspan(3.864, 4.301, label= 'F410', alpha = 0.25, color = 'orange')
                    ax3.axvspan(3.88, 4.986, label= 'F444', color = 'r', alpha = .25)
                    ax3.axvspan(2.416, 3.127, label= 'F277', color = 'g', alpha = .25)

                    #Illustrate a detector gap
                    #plt.axvspan(3.26,4.78,color = 'grey', alpha = 0.75)

                    ax3.axvspan(1.755, 2.226, label= 'F200', color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
                    ax3.axvspan(1.331, 1.668, label= 'F150', color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
                    ax3.axvspan(1.013, 1.282, label= 'F115', color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)

                    ax3.set_xlabel(r'Wavelength[$\mu$m]')
                    ax3.set_ylabel(r'$F_{\lambda}$')
                    ax3.set_xlim(.55,5.50)
                    ax3.set_ylim(low_min,scale)





                    hdu = fits.open(d2)
                    datap2 = hdu[1].data
                    #55to550
                    xs = np.linspace(.55, 5.5, int(1e4))
                    spectra = np.zeros(( datap2.shape[0], int(1e4)))
                    for x in np.arange(datap2.shape[0]):
                        inter = np.interp(xs, wave_1d, datap2[x] )
                        spectra[x, :] = inter


                    vmin = np.median(datap2) - val * np.std(datap2)
                    vmax = np.median(datap2) + val * np.std(datap2)


                    ax2.imshow(spectra , cmap = 'gray', vmin = vmin, vmax = vmax, origin = 'lower', aspect = 'auto')

                    ax2.set_xticks([])
                    ax2.set_yticks([])
    ###




            elif len(prism)==0:
                mgrat3 = glob.glob(f'/home/kelcey/JWST_test_code/updated_sources/p{pointing}/'+
                         f'p{pointing}_G395M_{int(mptids[n])}_*')
                if len(mgrat3)!=0:
                   # print(f'M grating available for source {obj}')

                    if mgrat3[0][-8] == 's':
                        d1 = mgrat3[1]
                        d2 = mgrat3[0]
                       # print(mgrat3, mptids[n], '1D:', d1)

                        mgratss.append(mptids[n])

                        hdu1 = fits.open(d1)
                        datap1 = hdu1[1].data
                        wave_1d = datap1['WAVELENGTH']
                        flx_1d  = datap1['FLUX']
                        pix_1d  = np.arange(len(wave_1d))

                        datap1 = hdu1[1].data
                        flux = []
                        for f in flx_1d:
                            if f<datmin:
                                flux.append(np.nan)
                            else:
                                flux.append(f*1e-9)

                        flux_e = []
                        for f in datap1['FLUX_ERROR']:
                            if f>emax:
                                flux_e.append(np.nan)
                            else:
                                flux_e.append(f*1e-9)

                        ax3.plot(datap1['WAVELENGTH'], flux, clip_on = False)
                        ax3.fill_between(datap1['WAVELENGTH'], np.array(flux)-np.array(flux_e), 
                             np.array(flux)+np.array(flux_e), color = 'c', alpha  = 0.35, clip_on = False)
                        ax3.axvspan(3.14, 3.98, label= 'F356', color = 'y', alpha = .25)
                        ax3.axvspan(3.864, 4.301, label= 'F410', alpha = 0.25, color = 'orange')
                        ax3.axvspan(3.88, 4.986, label= 'F444', color = 'r', alpha = .25)
                        ax3.axvspan(2.416, 3.127, label= 'F277', color = 'g', alpha = .25)

                        #Illustrate a detector gap
                        #plt.axvspan(3.26,4.78,color = 'grey', alpha = 0.75)

                        ax3.axvspan(1.755, 2.226, label= 'F200', color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
                        ax3.axvspan(1.331, 1.668, label= 'F150', color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
                        ax3.axvspan(1.013, 1.282, label= 'F115', color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)

                        ax3.set_xlabel(r'Wavelength[$\mu$m]')
                        ax3.set_ylabel(r'$F_{\lambda}$')
                        ax3.set_xlim(.55,5.50)
                        ax3.set_ylim(low_min,scale)





                        hdu = fits.open(d2)
                        datap2 = hdu[1].data
                        #55to550
                        xs = np.linspace(.55, 5.5, int(1e4))
                        spectra = np.zeros(( datap2.shape[0], int(1e4)))
                        for x in np.arange(datap2.shape[0]):
                            inter = np.interp(xs, wave_1d, datap2[x] )
                            spectra[x, :] = inter


                        vmin = np.median(datap2) - val * np.std(datap2)
                        vmax = np.median(datap2) + val * np.std(datap2)


                        ax2.imshow(spectra , cmap = 'gray', vmin = vmin, vmax = vmax, origin = 'lower', aspect = 'auto')

                        ax2.set_xticks([])
                        ax2.set_yticks([])


                    elif mgrat3[0][-8] == 'x':
                        d1 = mgrat3[0]
                        d2 = mgrat3[1]
                       # print(mgrat3, mptids[n], '1D:', d1)

                        mgratss.append(mptids[n])

                        hdu1 = fits.open(d1)
                        datap1 = hdu1[1].data
                        wave_1d = datap1['WAVELENGTH']
                        flx_1d  = datap1['FLUX']
                        pix_1d  = np.arange(len(wave_1d))

                        datap1 = hdu1[1].data
                        flux = []
                        for f in flx_1d:
                            if f<datmin:
                                flux.append(np.nan)
                            else:
                                flux.append(f*1e-9)

                        flux_e = []
                        for f in datap1['FLUX_ERROR']:
                            if f>emax:
                                flux_e.append(np.nan)
                            else:
                                flux_e.append(f*1e-9)

                        ax3.plot(datap1['WAVELENGTH'], flux, clip_on = False)
                        ax3.fill_between(datap1['WAVELENGTH'], np.array(flux)-np.array(flux_e), 
                             np.array(flux)+np.array(flux_e), color = 'c', alpha  = 0.35, clip_on = False)
                        ax3.axvspan(3.14, 3.98, label= 'F356', color = 'y', alpha = .25)
                        ax3.axvspan(3.864, 4.301, label= 'F410', alpha = 0.25, color = 'orange')
                        ax3.axvspan(3.88, 4.986, label= 'F444', color = 'r', alpha = .25)
                        ax3.axvspan(2.416, 3.127, label= 'F277', color = 'g', alpha = .25)

                        #Illustrate a detector gap
                        #plt.axvspan(3.26,4.78,color = 'grey', alpha = 0.75)

                        ax3.axvspan(1.755, 2.226, label= 'F200', color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
                        ax3.axvspan(1.331, 1.668, label= 'F150', color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
                        ax3.axvspan(1.013, 1.282, label= 'F115', color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)

                        ax3.set_xlabel(r'Wavelength[$\mu$m]')
                        ax3.set_ylabel(r'$F_{\lambda}$')
                        ax3.set_xlim(.55,5.50)
                        ax3.set_ylim(low_min,scale)





                        hdu = fits.open(d2)
                        datap2 = hdu[1].data
                        #55to550
                        xs = np.linspace(.55, 5.5, int(1e4))
                        spectra = np.zeros(( datap2.shape[0], int(1e4)))
                        for x in np.arange(datap2.shape[0]):
                            inter = np.interp(xs, wave_1d, datap2[x] )
                            spectra[x, :] = inter


                        vmin = np.median(datap2) - val * np.std(datap2)
                        vmax = np.median(datap2) + val * np.std(datap2)


                        ax2.imshow(spectra , cmap = 'gray', vmin = vmin, vmax = vmax, origin = 'lower', aspect = 'auto')

                        ax2.set_xticks([])
                        ax2.set_yticks([])

                elif len(mgrat3) == 0:
                    check == 1
                   # print(f'Download files for source {obj}')
        if check == 1:

            pointing = int(cathits[n][-1][-1])
            #if:
            ps = []
            for h in cathits[n]:
                p = h[-1]
                try:
                    int(p)
                    if p !=pointing:
                        ps.append(p)
                except:
                    y = True






            if len(ps)!= 0:
                for p in ps:
                    pointing = p

                    ###

                    files = glob.glob(f'/home/kelcey/JWST_test_code/updated_sources/p{pointing}/*')
                    if len(files)==0:
                        #print(f'Download files for source {obj}')
                        check == 1
                    else:
                        prism = glob.glob(f'/home/kelcey/JWST_test_code/updated_sources/p{pointing}/'+
                                     f'p{pointing}_PRISM_{int(mptids[n])}_*')

                       # prismss.append(mptids[n])
                        #print(len(prism))
                        if len(prism)!=0:
                           # print('Prism available')
                            if prism[0][-8] == 's':
                                d1 = prism[1]
                                d2 = prism[0]

                                prismss.append(mptids[n])

                                hdu1 = fits.open(d1)
                                datap1 = hdu1[1].data
                                wave_1d = datap1['WAVELENGTH']
                                flx_1d  = datap1['FLUX']
                                pix_1d  = np.arange(len(wave_1d))

                                datap1 = hdu1[1].data
                                flux = []
                                for f in flx_1d:
                                    if f<datmin:
                                        flux.append(np.nan)
                                    else:
                                        flux.append(f*1e-9)

                                flux_e = []
                                for f in datap1['FLUX_ERROR']:
                                    if f>emax:
                                        flux_e.append(np.nan)
                                    else:
                                        flux_e.append(f*1e-9)

                                ax3.plot(datap1['WAVELENGTH'], flux, clip_on = False)
                                ax3.fill_between(datap1['WAVELENGTH'], np.array(flux)-np.array(flux_e), 
                                     np.array(flux)+np.array(flux_e), color = 'c', alpha  = 0.35, clip_on = False)
                                ax3.axvspan(3.14, 3.98, label= 'F356', color = 'y', alpha = .25)
                                ax3.axvspan(3.864, 4.301, label= 'F410', alpha = 0.25, color = 'orange')
                                ax3.axvspan(3.88, 4.986, label= 'F444', color = 'r', alpha = .25)
                                ax3.axvspan(2.416, 3.127, label= 'F277', color = 'g', alpha = .25)

                                #Illustrate a detector gap
                                #plt.axvspan(3.26,4.78,color = 'grey', alpha = 0.75)

                                ax3.axvspan(1.755, 2.226, label= 'F200', color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
                                ax3.axvspan(1.331, 1.668, label= 'F150', color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
                                ax3.axvspan(1.013, 1.282, label= 'F115', color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)

                                ax3.set_xlabel(r'Wavelength[$\mu$m]')
                                ax3.set_ylabel(r'$F_{\lambda}$')
                                ax3.set_xlim(.55,5.50)
                                ax3.set_ylim(low_min,scale)





                                hdu = fits.open(d2)
                                datap2 = hdu[1].data
                                #55to550
                                xs = np.linspace(.55, 5.5, int(1e4))
                                spectra = np.zeros(( datap2.shape[0], int(1e4)))
                                for x in np.arange(datap2.shape[0]):
                                    inter = np.interp(xs, wave_1d, datap2[x] )
                                    spectra[x, :] = inter


                                vmin = np.median(datap2) - val * np.std(datap2)
                                vmax = np.median(datap2) + val * np.std(datap2)


                                ax2.imshow(spectra , cmap = 'gray', vmin = vmin, vmax = vmax, origin = 'lower', aspect = 'auto')

                                ax2.set_xticks([])
                                ax2.set_yticks([])

                            elif prism[0][-8] == 'x':
                                d1 = prism[0]
                                d2 = prism[1]

                                prismss.append(mptids[n])

                                hdu1 = fits.open(d1)
                                datap1 = hdu1[1].data
                                wave_1d = datap1['WAVELENGTH']
                                flx_1d  = datap1['FLUX']
                                pix_1d  = np.arange(len(wave_1d))

                                datap1 = hdu1[1].data
                                flux = []
                                for f in flx_1d:
                                    if f<datmin:
                                        flux.append(np.nan)
                                    else:
                                        flux.append(f*1e-9)

                                flux_e = []
                                for f in datap1['FLUX_ERROR']:
                                    if f>emax:
                                        flux_e.append(np.nan)
                                    else:
                                        flux_e.append(f*1e-9)

                                ax3.plot(datap1['WAVELENGTH'], flux, clip_on = False)
                                ax3.fill_between(datap1['WAVELENGTH'], np.array(flux)-np.array(flux_e), 
                                     np.array(flux)+np.array(flux_e), color = 'c', alpha  = 0.35, clip_on = False)
                                ax3.axvspan(3.14, 3.98, label= 'F356', color = 'y', alpha = .25)
                                ax3.axvspan(3.864, 4.301, label= 'F410', alpha = 0.25, color = 'orange')
                                ax3.axvspan(3.88, 4.986, label= 'F444', color = 'r', alpha = .25)
                                ax3.axvspan(2.416, 3.127, label= 'F277', color = 'g', alpha = .25)

                                #Illustrate a detector gap
                                #plt.axvspan(3.26,4.78,color = 'grey', alpha = 0.75)

                                ax3.axvspan(1.755, 2.226, label= 'F200', color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
                                ax3.axvspan(1.331, 1.668, label= 'F150', color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
                                ax3.axvspan(1.013, 1.282, label= 'F115', color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)

                                ax3.set_xlabel(r'Wavelength[$\mu$m]')
                                ax3.set_ylabel(r'$F_{\lambda}$')
                                ax3.set_xlim(.55,5.50)
                                ax3.set_ylim(low_min,scale)





                                hdu = fits.open(d2)
                                datap2 = hdu[1].data
                                #55to550
                                xs = np.linspace(.55, 5.5, int(1e4))
                                spectra = np.zeros(( datap2.shape[0], int(1e4)))
                                for x in np.arange(datap2.shape[0]):
                                    inter = np.interp(xs, wave_1d, datap2[x] )
                                    spectra[x, :] = inter


                                vmin = np.median(datap2) - val * np.std(datap2)
                                vmax = np.median(datap2) + val * np.std(datap2)


                                ax2.imshow(spectra , cmap = 'gray', vmin = vmin, vmax = vmax, origin = 'lower', aspect = 'auto')

                                ax2.set_xticks([])
                                ax2.set_yticks([])


                        elif len(prism)==0:
                            mgrat3 = glob.glob(f'/home/kelcey/JWST_test_code/updated_sources/p{pointing}/'+
                                     f'p{pointing}_G395M_{int(mptids[n])}_*')
                            if len(mgrat3)!=0:
                               # print(f'M grating available for source {obj}')

                                if mgrat3[0][-8] == 's':
                                    d1 = mgrat3[1]
                                    d2 = mgrat3[0]
                                   # print(mgrat3, mptids[n], '1D:', d1)
                                    mgratss.append(mptids[n])

                                    hdu1 = fits.open(d1)
                                    datap1 = hdu1[1].data
                                    wave_1d = datap1['WAVELENGTH']
                                    flx_1d  = datap1['FLUX']
                                    pix_1d  = np.arange(len(wave_1d))

                                    datap1 = hdu1[1].data
                                    flux = []
                                    for f in flx_1d:
                                        if f<datmin:
                                            flux.append(np.nan)
                                        else:
                                            flux.append(f*1e-9)

                                    flux_e = []
                                    for f in datap1['FLUX_ERROR']:
                                        if f>emax:
                                            flux_e.append(np.nan)
                                        else:
                                            flux_e.append(f*1e-9)

                                    ax3.plot(datap1['WAVELENGTH'], flux, clip_on = False)
                                    ax3.fill_between(datap1['WAVELENGTH'], np.array(flux)-np.array(flux_e), 
                                         np.array(flux)+np.array(flux_e), color = 'c', alpha  = 0.35, clip_on = False)
                                    ax3.axvspan(3.14, 3.98, label= 'F356', color = 'y', alpha = .25)
                                    ax3.axvspan(3.864, 4.301, label= 'F410', alpha = 0.25, color = 'orange')
                                    ax3.axvspan(3.88, 4.986, label= 'F444', color = 'r', alpha = .25)
                                    ax3.axvspan(2.416, 3.127, label= 'F277', color = 'g', alpha = .25)

                                    #Illustrate a detector gap
                                    #plt.axvspan(3.26,4.78,color = 'grey', alpha = 0.75)

                                    ax3.axvspan(1.755, 2.226, label= 'F200', color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
                                    ax3.axvspan(1.331, 1.668, label= 'F150', color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
                                    ax3.axvspan(1.013, 1.282, label= 'F115', color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)

                                    ax3.set_xlabel(r'Wavelength[$\mu$m]')
                                    ax3.set_ylabel(r'$F_{\lambda}$')
                                    ax3.set_xlim(.55,5.50)
                                    ax3.set_ylim(low_min,scale)





                                    hdu = fits.open(d2)
                                    datap2 = hdu[1].data
                                    #55to550
                                    xs = np.linspace(.55, 5.5, int(1e4))
                                    spectra = np.zeros(( datap2.shape[0], int(1e4)))
                                    for x in np.arange(datap2.shape[0]):
                                        inter = np.interp(xs, wave_1d, datap2[x] )
                                        spectra[x, :] = inter


                                    vmin = np.median(datap2) - val * np.std(datap2)
                                    vmax = np.median(datap2) + val * np.std(datap2)


                                    ax2.imshow(spectra , cmap = 'gray', vmin = vmin, vmax = vmax, origin = 'lower', aspect = 'auto')

                                    ax2.set_xticks([])
                                    ax2.set_yticks([])


                                elif mgrat3[0][-8] == 'x':
                                    d1 = mgrat3[0]
                                    d2 = mgrat3[1]
                                   # print(mgrat3, mptids[n], '1D:', d1)
                                    hdu1 = fits.open(d1)
                                    datap1 = hdu1[1].data
                                    wave_1d = datap1['WAVELENGTH']
                                    flx_1d  = datap1['FLUX']
                                    pix_1d  = np.arange(len(wave_1d))

                                    datap1 = hdu1[1].data
                                    flux = []
                                    for f in flx_1d:
                                        if f<datmin:
                                            flux.append(np.nan)
                                        else:
                                            flux.append(f*1e-9)

                                    flux_e = []
                                    for f in datap1['FLUX_ERROR']:
                                        if f>emax:
                                            flux_e.append(np.nan)
                                        else:
                                            flux_e.append(f*1e-9)

                                    ax3.plot(datap1['WAVELENGTH'], flux,  clip_on = False)
                                    ax3.fill_between(datap1['WAVELENGTH'], np.array(flux)-np.array(flux_e), 
                                         np.array(flux)+np.array(flux_e), color = 'c', alpha  = 0.35, clip_on = False)
                                    ax3.axvspan(3.14, 3.98, label= 'F356', color = 'y', alpha = .25)
                                    ax3.axvspan(3.864, 4.301, label= 'F410', alpha = 0.25, color = 'orange')
                                    ax3.axvspan(3.88, 4.986, label= 'F444', color = 'r', alpha = .25)
                                    ax3.axvspan(2.416, 3.127, label= 'F277', color = 'g', alpha = .25)

                                    #Illustrate a detector gap
                                    #plt.axvspan(3.26,4.78,color = 'grey', alpha = 0.75)

                                    ax3.axvspan(1.755, 2.226, label= 'F200', color = 'grey', alpha = 0.55)#color = 'cyan', alpha = .25)
                                    ax3.axvspan(1.331, 1.668, label= 'F150', color = 'grey', alpha = 0.45)#color = 'blue', alpha = .25)
                                    ax3.axvspan(1.013, 1.282, label= 'F115', color = 'grey', alpha = 0.25)#color = 'purple', alpha = .25)

                                    ax3.set_xlabel(r'Wavelength[$\mu$m]')
                                    ax3.set_ylabel(r'$F_{\lambda}$')
                                    ax3.set_xlim(.55,5.50)
                                    ax3.set_ylim(low_min,scale)

                                    #ax3.set_xlim(.55,5.5) 




                                    hdu = fits.open(d2)
                                    dat
                                    ap2 = hdu[1].data
                                    #55to550
                                    xs = np.linspace(.55, 5.5, int(1e4))
                                    spectra = np.zeros(( datap2.shape[0], int(1e4)))
                                    for x in np.arange(datap2.shape[0]):
                                        inter = np.interp(xs, wave_1d, datap2[x] )
                                        spectra[x, :] = inter


                                    vmin = np.median(datap2) - val * np.std(datap2)
                                    vmax = np.median(datap2) + val * np.std(datap2)


                                    ax2.imshow(spectra , cmap = 'gray', vmin = vmin, vmax = vmax, origin = 'lower', aspect = 'auto')

                                    ax2.set_xticks([])
                                    ax2.set_yticks([])
                                    #plt.show()
                                    #plt.close()
                                    #plt.figure();

                            elif len(mgrat3) == 0:
                                check += 1
                               # print(f'Download files for source {obj}')


                    ###nircam9-90381

            elif len(ps) == 0:
                print(f'Download files for source {obj}')
                
def log10err(measurement, error):
    """
    Computes the error on a measurement in log 10 space
    ---
    PARAMS
    ---
    measurement: original measurement
    
    error: original error on the measurement
    ---
    RETURNS
    ----
    new error on the measurement in log10 space
    """
    return (1/np.log(10)) * (error/measurement)
    

__all__ = ["get_color_table", "load_photometry", 'jon_plot', "cut_sides", "get_ew", "get_ew_277", "get_ew_red_only_and_277", "get_ew_red_only", "plot_class", "plot_em_all", "get_sed", 'reject_outliers', "load_spectra", "baseline_correction",
          "identify_lines", "calculate_redshifts", 'filter_from_zwave', "plot_interplolated", 'log10err']